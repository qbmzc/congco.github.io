---
title: Redis-Cluster集群:docker-compose方式
date: 2021-03-11
categories:
  - Java
tags:
  - Redis
---

![pkkm6p](https://gitee.com/snowyan/image/raw/master/md/wallhaven-pkkm6p.png)

<!-- more -->

## 环境

```bash
         .-/+oossssoo+/-.               zc@ns-01 
        `:+ssssssssssssssssss+:`           -------- 
      -+ssssssssssssssssssyyssss+-         OS: Ubuntu 18.04.1 LTS x86_64 
    .ossssssssssssssssssdMMMNysssso.       Host: HP Z238 Microtower Workstation 
   /ssssssssssshdmmNNmmyNMMMMhssssss/      Kernel: 4.15.0-128-generic 
  +ssssssssshmydMMMMMMMNddddyssssssss+     Uptime: 66 days, 4 hours, 48 mins 
 /sssssssshNMMMyhhyyyyhmNMMMNhssssssss/    Packages: 648 
.ssssssssdMMMNhsssssssssshNMMMdssssssss.   Shell: bash 4.4.19 
+sssshhhyNMMNyssssssssssssyNMMMysssssss+   Terminal: /dev/pts/0 
ossyNMMMNyMMhsssssssssssssshmmmhssssssso   CPU: Intel Xeon E3-1225 v6 (4) @ 3.700GHz 
ossyNMMMNyMMhsssssssssssssshmmmhssssssso   GPU: Intel HD Graphics P630 
+sssshhhyNMMNyssssssssssssyNMMMysssssss+   Memory: 5652MiB / 48083MiB 
.ssssssssdMMMNhsssssssssshNMMMdssssssss. 
 /sssssssshNMMMyhhyyyyhdNMMMNhssssssss/                            
  +sssssssssdmydMMMMMMMMddddyssssssss+ 
   /ssssssssssshdmNNNNmyNMMMMhssssss/ 
    .ossssssssssssssssssdMMMNysssso. 
      -+sssssssssssssssssyyyssss+- 
        `:+ssssssssssssssssss+:` 
            .-/+oossssoo+/-. 

```

_默认系统已安装过`docker&docker-compose`_ 

## 步骤

1. 下载`redis`镜像
2. 编写`redis`配置文件
3. 编写`docker-compose.yml`模板文件
4. 创建并启动容器
5. 创建集群
6. 集群相关命令`redis-cli`

## 配置文件

```bash
sudo mkdir -p /usr/local/docker-redis/redis-cluster
# 进入文件夹，，创建配置文件
cd /usr/local/docker-redis/redis-cluster/
vim redis-cluster.tmpl
```

### 模板文件：`redis-cluster.tmpl`

```tmpl
port ${PORT}
requirepass zc0417
masterauth zc0417
protected-mode no
daemonize no
appendonly yes
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 15000
cluster-announce-ip 192.168.9.100
cluster-announce-port ${PORT}
cluster-announce-bus-port 1${PORT}
```



### 文件说明：

- `port`：节点端口；
- `requirepass`：添加访问认证；
- `masterauth`：如果主节点开启了访问认证，从节点访问主节点需要认证；
- `protected-mode`：保护模式，默认值 yes，即开启。开启保护模式以后，需配置 `bind ip` 或者设置访问密码；关闭保护模式，外部网络可以直接访问；
- `daemonize`：是否以守护线程的方式启动（后台启动），默认 no；
- `appendonly`：是否开启 AOF 持久化模式，默认 no；
- `cluster-enabled`：是否开启集群模式，默认 no；
- `cluster-config-file`：集群节点信息文件；
- `cluster-node-timeout`：集群节点连接超时时间；
- `cluster-announce-ip`：集群节点 IP，填写宿主机的 IP；
- `cluster-announce-port`：集群节点映射端口；
- `cluster-announce-bus-port`：集群节点总线端口。

## 生成配置文件及目录

在`192.168.9.100`执行

```bash
for port in `seq 6371 6373`; do \
  mkdir -p ${port}/conf \
  && PORT=${port} envsubst < redis-cluster.tmpl > ${port}/conf/redis.conf \
  && mkdir -p ${port}/data;\
done
```

在`192.168.9.151`执行

```bash
for port in `seq 6374 6376`; do \
  mkdir -p ${port}/conf \
  && PORT=${port} envsubst < redis-cluster.tmpl > ${port}/conf/redis.conf \
  && mkdir -p ${port}/data;\
done
```

以上命令可以保存为`shell`脚本，便于以后使用，`sh config.sh`

执行之后会发现在当前目录下生成对应的以端口为目录名称及配置文件

```bash
zc@zc:/usr/local/docker-redis/redis-cluster$ tree
.
├── 6374
│   ├── conf
│   │   └── redis.conf
│   └── data
├── 6375
│   ├── conf
│   │   └── redis.conf
│   └── data
├── 6376
│   ├── conf
│   │   └── redis.conf
│   └── data
├── config.sh
├── docker-compose.yml
└── redis-cluster.tmpl
```

## `redis.conf`

```conf
port 6374
protected-mode no
daemonize no
appendonly yes
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 15000
cluster-announce-ip 192.168.9.151
cluster-announce-port 6374
cluster-announce-bus-port 16374
```





## `docker-compose.yml`

```yml
version: "3.3"

services:
  redis-6371:
    image: redis
    container_name: redis-6371
    restart: always
    network_mode: "host"
    volumes:
    - /usr/local/docker-redis/redis-cluster/6371/conf/redis.conf:/usr/local/etc/redis/redis.conf
    - /usr/local/docker-redis/redis-cluster/6371/data:/data
    command: redis-server /usr/local/etc/redis/redis.conf

  redis-6372:
    image: redis
    container_name: redis-6372
    restart: always
    network_mode: "host"
    volumes:
      - /usr/local/docker-redis/redis-cluster/6372/conf/redis.conf:/usr/local/etc/redis/redis.conf
      - /usr/local/docker-redis/redis-cluster/6372/data:/data
    command: redis-server /usr/local/etc/redis/redis.conf

  redis-6373:
    image: redis
    container_name: redis-6373
    restart: always
    network_mode: "host"
    volumes:
      - /usr/local/docker-redis/redis-cluster/6373/conf/redis.conf:/usr/local/etc/redis/redis.conf
      - /usr/local/docker-redis/redis-cluster/6373/data:/data
    command: redis-server /usr/local/etc/redis/redis.conf
```

## 启动

```bash
zc@ns-01:/usr/local/docker-redis/redis-cluster$ docker-compose up -d
Pulling redis-6371 (redis:)...
latest: Pulling from library/redis
a076a628af6f: Pull complete
f40dd07fe7be: Pull complete
ce21c8a3dbee: Pull complete
ee99c35818f8: Pull complete
56b9a72e68ff: Pull complete
3f703e7f380f: Pull complete
Digest: sha256:0f97c1c9daf5b69b93390ccbe8d3e2971617ec4801fd0882c72bf7cad3a13494
Status: Downloaded newer image for redis:latest
Creating redis-6371 ... done
Creating redis-6372 ... done
Creating redis-6373 ... done
```



## 集群命令



```bash
redis-cli -a zc0417 --cluster create 192.168.9.100:6371 192.168.9.100:6372 192.168.9.100:6373 192.168.9.151:6374 192.168.9.151:6375 192.168.9.151:6376 --cluster-replicas 1
# 输出信息
>>> Performing hash slots allocation on 6 nodes...
Master[0] -> Slots 0 - 5460
Master[1] -> Slots 5461 - 10922
Master[2] -> Slots 10923 - 16383
Adding replica 192.168.9.151:6376 to 192.168.9.100:6371
Adding replica 192.168.9.100:6373 to 192.168.9.151:6374
Adding replica 192.168.9.151:6375 to 192.168.9.100:6372
M: 8045e24b22f70bb0ce30253ad9209981ef067e58 192.168.9.100:6371
   slots:[0-5460] (5461 slots) master
M: c7d5f26e05eec43235871d96cb0f9a090d3c0422 192.168.9.100:6372
   slots:[10923-16383] (5461 slots) master
S: 2366bb4df9e72eaf6f0a1e82544a02e1ea58bc23 192.168.9.100:6373
   replicates db91be5f7eb9e876ad2c835d0faa7954af4bc7cc
M: db91be5f7eb9e876ad2c835d0faa7954af4bc7cc 192.168.9.151:6374
   slots:[5461-10922] (5462 slots) master
S: 3d88373159f5ff5a466e89432240e9f1c9a05d72 192.168.9.151:6375
   replicates c7d5f26e05eec43235871d96cb0f9a090d3c0422
S: 060c9aba9954902c609c0664003c297597700c53 192.168.9.151:6376
   replicates 8045e24b22f70bb0ce30253ad9209981ef067e58
Can I set the above configuration? (type 'yes' to accept): yes
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join
.....
>>> Performing Cluster Check (using node 192.168.9.100:6371)
M: 8045e24b22f70bb0ce30253ad9209981ef067e58 192.168.9.100:6371
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 3d88373159f5ff5a466e89432240e9f1c9a05d72 192.168.9.151:6375
   slots: (0 slots) slave
   replicates c7d5f26e05eec43235871d96cb0f9a090d3c0422
S: 2366bb4df9e72eaf6f0a1e82544a02e1ea58bc23 192.168.9.100:6373
   slots: (0 slots) slave
   replicates db91be5f7eb9e876ad2c835d0faa7954af4bc7cc
M: db91be5f7eb9e876ad2c835d0faa7954af4bc7cc 192.168.9.151:6374
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
M: c7d5f26e05eec43235871d96cb0f9a090d3c0422 192.168.9.100:6372
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 060c9aba9954902c609c0664003c297597700c53 192.168.9.151:6376
   slots: (0 slots) slave
   replicates 8045e24b22f70bb0ce30253ad9209981ef067e58
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
```

注意，这里使用的`redis`版本，  `Redis Cluster` 在5.0之后取消了ruby脚本`redis-trib.rb`的支持（手动命令行添加集群的方式不变），集合到`redis-cli`里，避免了再安装`ruby`的相关环境。直接使用`redis-clit`的参数`--cluster` 来取代。为方便自己后面查询就说明下如何使用该命令进行`Cluster`的创建和管理。

## `redis-cli`

```bash
redis-cli --cluster help
Cluster Manager Commands:
  create         host1:port1 ... hostN:portN   #创建集群
                 --cluster-replicas <arg>      #从节点个数
  check          host:port                     #检查集群
                 --cluster-search-multiple-owners #检查是否有槽同时被分配给了多个节点
  info           host:port                     #查看集群状态
  fix            host:port                     #修复集群
                 --cluster-search-multiple-owners #修复槽的重复分配问题
  reshard        host:port                     #指定集群的任意一节点进行迁移slot，重新分slots
                 --cluster-from <arg>          #需要从哪些源节点上迁移slot，可从多个源节点完成迁移，以逗号隔开，传递的是节点的node id，还可以直接传递--from all，这样源节点就是集群的所有节点，不传递该参数的话，则会在迁移过程中提示用户输入
                 --cluster-to <arg>            #slot需要迁移的目的节点的node id，目的节点只能填写一个，不传递该参数的话，则会在迁移过程中提示用户输入
                 --cluster-slots <arg>         #需要迁移的slot数量，不传递该参数的话，则会在迁移过程中提示用户输入。
                 --cluster-yes                 #指定迁移时的确认输入
                 --cluster-timeout <arg>       #设置migrate命令的超时时间
                 --cluster-pipeline <arg>      #定义cluster getkeysinslot命令一次取出的key数量，不传的话使用默认值为10
                 --cluster-replace             #是否直接replace到目标节点
  rebalance      host:port                                      #指定集群的任意一节点进行平衡集群节点slot数量 
                 --cluster-weight <node1=w1...nodeN=wN>         #指定集群节点的权重
                 --cluster-use-empty-masters                    #设置可以让没有分配slot的主节点参与，默认不允许
                 --cluster-timeout <arg>                        #设置migrate命令的超时时间
                 --cluster-simulate                             #模拟rebalance操作，不会真正执行迁移操作
                 --cluster-pipeline <arg>                       #定义cluster getkeysinslot命令一次取出的key数量，默认值为10
                 --cluster-threshold <arg>                      #迁移的slot阈值超过threshold，执行rebalance操作
                 --cluster-replace                              #是否直接replace到目标节点
  add-node       new_host:new_port existing_host:existing_port  #添加节点，把新节点加入到指定的集群，默认添加主节点
                 --cluster-slave                                #新节点作为从节点，默认随机一个主节点
                 --cluster-master-id <arg>                      #给新节点指定主节点
  del-node       host:port node_id                              #删除给定的一个节点，成功后关闭该节点服务
  call           host:port command arg arg .. arg               #在集群的所有节点执行相关命令
  set-timeout    host:port milliseconds                         #设置cluster-node-timeout
  import         host:port                                      #将外部redis数据导入集群
                 --cluster-from <arg>                           #将指定实例的数据导入到集群
                 --cluster-copy                                 #migrate时指定copy
                 --cluster-replace                              #migrate时指定replace
  help           

For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster.
```

## 添加一个节点到集群

```bash
redis-cli --cluster add-node 192.168.9.123:6379 192.168.9.100:6371
# 说明：为一个指定集群添加节点，需要先连到该集群的任意一个节点IP（192.168.9.100:6371），再把新节点加入。该2个参数的顺序有要求：新加入的节点放前

>>> Adding node 192.168.9.123:6379 to cluster 192.168.9.100:6371
>>> Performing Cluster Check (using node 192.168.9.100:6371)
M: 8045e24b22f70bb0ce30253ad9209981ef067e58 192.168.9.100:6371
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 3d88373159f5ff5a466e89432240e9f1c9a05d72 192.168.9.151:6375
   slots: (0 slots) slave
   replicates c7d5f26e05eec43235871d96cb0f9a090d3c0422
S: 2366bb4df9e72eaf6f0a1e82544a02e1ea58bc23 192.168.9.100:6373
   slots: (0 slots) slave
   replicates db91be5f7eb9e876ad2c835d0faa7954af4bc7cc
M: db91be5f7eb9e876ad2c835d0faa7954af4bc7cc 192.168.9.151:6374
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
M: c7d5f26e05eec43235871d96cb0f9a090d3c0422 192.168.9.100:6372
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 060c9aba9954902c609c0664003c297597700c53 192.168.9.151:6376
   slots: (0 slots) slave
   replicates 8045e24b22f70bb0ce30253ad9209981ef067e58
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
>>> Send CLUSTER MEET to node 192.168.9.123:6379 to make it join the cluster.
[OK] New node added correctly.
```

## `Redis-Cluster`集群

`redis`的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台`redis`服务器都存储相同的数据，很浪费内存，所以在`redis3.0`上加入了`cluster`模式，实现的`redis`的分布式存储，也就是说每台`redis`节点上存储不同的内容。

`Redis-Cluster`采用无中心结构,它的特点如下：

所有的`redis`节点彼此互联`(PING-PONG`机制),内部使用二进制协议优化传输速度和带宽。
节点的`fail`是通过集群中超过半数的节点检测失效时才生效。
客户端与`redis`节点直连,不需要中间代理层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。
工作方式：

在`redis`的每一个节点上，都有这么两个东西，一个是插槽（`slot`），它的的取值范围是：0-16383。还有一个就是`cluster`，可以理解为是一个集群管理的插件。当我们的存取的key到达的时候，`redis`会根据`crc16`的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。

为了保证高可用，`redis-cluster`集群引入了主从模式，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点ping一个主节点A时，如果半数以上的主节点与A通信超时，那么认为主节点A宕机了。如果主节点A和它的从节点`A1`都宕机了，那么该集群就无法再提供服务了。

Redis集群方案基于分而治之的思想。Redis中数据都是以Key-Value形式存储的，而不同Key的数据之间是相互独立的。因此可以将Key按照某种规则划分成多个分区，将不同分区的数据存放在不同的节点上。这个方案类似数据结构中哈希表的结构。在Redis集群的实现中，使用哈希算法（公式是CRC16(Key) mod 16383）将Key映射到0~16383范围的整数。这样每个整数对应存储了若干个Key-Value数据，这样一个整数对应的抽象存储称为一个槽（slot）。每个Redis Cluster的节点——准确讲是master节点——负责一定范围的槽，所有节点组成的集群覆盖了0~16383整个范围的槽。

## Slave

上面的方案只是解决了性能扩展的问题，集群的故障容错能力并没有提升。提高容错能力的方法一般为使用某种备份/冗余手段。负责一定数量的槽的节点被称为master节点。为了增加集群稳定性，每个master节点可以配置若干个备份节点——称为slave节点。Slave节点一般作为冷备份保存master节点的数据，在master节点宕机时替换master节点。在一些数据访问压力比较大的情况下，slave节点也可以提供读取数据的功能，不过slave节点的数据实时性会略差一下。而写数据的操作则只能通过master节点进行。

## 节点通信
尽管不同节点存储的数据相互独立，这些节点仍然需要相互通信以同步节点状态信息。Redis集群采用P2P的Gossip协议，节点之间不断地通信交换信息，最终所有节点的状态都会达成一致。常用的Gossip消息有下面几种：  
ping消息：每个节点不断地向其他节点发起ping消息，用于检测节点是否在线和交换节点状态信息。  
pong消息：收到ping、meet消息时的响应消息。  
meet消息：新节点加入消息。  
fail消息：节点下线消息。  
forget消息：忘记节点消息，使一个节点下线。这个命令必须在60秒内在所有节点执行，否则超过60秒后该节点重新参与消息交换。实践中不建议直接使用forget命令来操作节点下线。

## 节点下线
当某个节点出现问题时，需要一定的传播时间让多数master节点认为该节点确实不可用，才能标记标记该节点真正下线。Redis集群的节点下线包括两个环节：主观下线（pfail）和客观下线（fail）。  
主观下线：当节点A在cluster-node-timeout时间内和节点B通信（ping-pong消息）一直失败，则节点A认为节点B不可用，标记为主观下线，并将状态消息传播给其他节点。  
客观下线：当一个节点被集群内多数master节点标记为主观下线后，则触发客观下线流程，标记该节点真正下线。
## 故障恢复
一个持有槽的master节点客观下线后，集群会从slave节点中选出一个提升为master节点来替换它。Redis集群使用选举-投票的算法来挑选slave节点。一个slave节点必须获得包括故障的master节点在内的多数master节点的投票后才能被提升为master节点。假设集群规模为3主3从，则必须至少有2个主节点存活才能执行故障恢复。如果部署时将2个主节点部署到同一台服务器上，则该服务器不幸宕机后集群无法执行故障恢复。  
默认情况下，Redis集群如果有master节点不可用，即有一些槽没有负责的节点，则整个集群不可用。也就是说当一个master节点故障，到故障恢复的这段时间，整个集群都处于不可用的状态。这对于一些业务来说是不可忍受的。可以在配置中将cluster-require-full-coverage配置为no，那么master节点故障时只会影响访问它负责的相关槽的数据，不影响对其他节点的访问。

## 持久化

## 一、redis持久化----两种方式

1、redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。

2、RDB，简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上；

3、AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。

4、其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。

5、如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。

## 二、redis持久化----RDB

1、RDB方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。

2、redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。

3、对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。

4、如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。

5、虽然RDB有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。所以，redis还提供了另一种持久化方式，那就是AOF。

## 三、redis持久化----AOF

1、AOF，英文是Append Only File，即只允许追加不允许改写的文件。

2、如前面介绍的，AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。

3、我们通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。

4、默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。

5如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。

6、因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。

7、在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性，这点大家可以放心。

8、AOF方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作redis时，不小心执行了FLUSHALL，导致redis内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要redis配置了AOF持久化方式，且AOF文件还没有被重写（rewrite），我们就可以用最快的速度暂停redis并编辑AOF文件，将最后一行的FLUSHALL命令删除，然后重启redis，就可以恢复redis的所有数据到FLUSHALL之前的状态了。是不是很神奇，这就是AOF持久化方式的好处之一。但是如果AOF文件已经被重写了，那就无法通过这种方法来恢复数据了。

9、虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。

如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。

10、如果运气比较差，AOF文件出现了被写坏的情况，也不必过分担忧，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件：

1.备份被写坏的AOF文件
2.运行redis-check-aof –fix进行修复
3.用diff -u来看下两个文件的差异，确认问题点
4.重启redis，加载修复后的AOF文件

## 四、redis持久化----AOF重写

1、AOF重写的内部运行原理，我们有必要了解一下。

2、在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。

3、与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。

4、当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。

5、当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。

## 五、redis持久化----如何选择RDB和AOF

1、对于我们应该选择RDB还是AOF，官方的建议是两个同时使用。这样可以提供更可靠的持久化方案。

2、redis的备份和还原，可以借助第三方的工具redis-dump。

六、Redis的两种持久化方式也有明显的缺点
1、RDB需要定时持久化，风险是可能会丢两次持久之间的数据，量可能很大。

2、AOF每秒fsync一次指令硬盘，如果硬盘IO慢，会阻塞父进程；风险是会丢失1秒多的数据；在Rewrite过程中，主进程把指令存到mem-buffer中，最后写盘时会阻塞主进程。

[持久化相关内容：https://blog.csdn.net/ljheee/article/details/76284082](https://blog.csdn.net/ljheee/article/details/76284082)